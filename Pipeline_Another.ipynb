{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "### our imports\n",
    "\n",
    "from src.utils import get_data_from_directory, get_files_directory_list\n",
    "from src.TFE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -nc \"http://www.timeseriesclassification.com/Downloads/Archives/Univariate2018_arff.zip\"\n",
    "#!unzip -q -n \"Univariate2018_arff.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:  ArrowHead\n",
      "X_train shape:  (36, 251)\n",
      "y_train shape:  (36,)\n",
      "X_test shape:   (175, 251)\n",
      "y_test shape:   (175,)\n"
     ]
    }
   ],
   "source": [
    "directory_list = get_files_directory_list()\n",
    "directory_list = sorted(directory_list)\n",
    "\n",
    "random_index = 5\n",
    "random_path = directory_list[random_index]\n",
    "\n",
    "X_train, X_test, y_train, y_test = get_data_from_directory(random_path)\n",
    "X_train = X_train.squeeze()\n",
    "y_train = y_train.squeeze()\n",
    "X_test = X_test.squeeze()\n",
    "y_test = y_test.squeeze()\n",
    "\n",
    "print('Dataset: ', random_path)\n",
    "print('X_train shape: ', X_train.shape)\n",
    "print('y_train shape: ', y_train.shape)\n",
    "print('X_test shape:  ', X_test.shape)\n",
    "print('y_test shape:  ', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = TopologicalFeaturesExtractor(\n",
    "    persistence_diagram_extractor=PersistenceDiagramsExtractor(takens_embedding_dim=3, \n",
    "                                                               takens_embedding_delay=10,\n",
    "                                                               homology_dimensions=(0, 1, 2)),\n",
    "    persistence_diagram_features=[HolesNumberFeature(),\n",
    "                                  MaxHoleLifeTimeFeature(),\n",
    "                                  RelevantHolesNumber(),\n",
    "                                  AverageHoleLifetimeFeature(),\n",
    "                                  SumHoleLifetimeFeature(),\n",
    "                                  PersistenceEntropyFeature(),\n",
    "                                  SimultaneousAliveHolesFeatue()])\n",
    "\n",
    "X_train_transformed = feature_extractor.fit_transform(X_train)\n",
    "X_test_transformed = feature_extractor.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_transformed shape:  (36, 21)\n",
      "X_test_transformed shape:   (175, 21)\n"
     ]
    }
   ],
   "source": [
    "print('X_train_transformed shape: ', X_train_transformed.shape)\n",
    "print('X_test_transformed shape:  ', X_test_transformed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7222222222222222\n",
      "Test accuracy:  0.4857142857142857\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"C\": [10**i for i in range(-2, 5)],\n",
    "              \"kernel\": [\"linear\", \"rbf\", \"sigmoid\", \"poly\"]}\n",
    "\n",
    "svc_cv = GridSearchCV(SVC(random_state=42), \n",
    "                      param_grid=parameters,\n",
    "                      cv=5,\n",
    "                      scoring='accuracy', \n",
    "                      n_jobs=-1)\n",
    "svc_cv.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"Train accuracy: \", accuracy_score(y_train, svc_cv.best_estimator_.predict(X_train_transformed)))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, svc_cv.best_estimator_.predict(X_test_transformed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  1.0\n",
      "Test accuracy:  0.5028571428571429\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"max_depth\": [2, 10, 15, 20, 25, 30, 35, 40, 45, 50, 70, 100, 120, 150],\n",
    "              \"n_estimators\": [20, 50, 100, 150, 200, 250]}\n",
    "svc_cv = GridSearchCV(XGBClassifier(n_jobs=-1, random_state=42), \n",
    "                      param_grid=parameters,\n",
    "                      cv=2,\n",
    "                      scoring='accuracy', \n",
    "                      n_jobs=-1)\n",
    "svc_cv.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"Train accuracy: \", accuracy_score(y_train, svc_cv.best_estimator_.predict(X_train_transformed)))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, svc_cv.best_estimator_.predict(X_test_transformed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.75\n",
      "Test accuracy:  0.5485714285714286\n"
     ]
    }
   ],
   "source": [
    "parameters = {\"n_neighbors\": [3, 5, 7, 11,]}\n",
    "\n",
    "knn_cv = GridSearchCV(KNeighborsClassifier(n_jobs=-1), \n",
    "                      param_grid=parameters,\n",
    "                      cv=5,\n",
    "                      scoring='accuracy', \n",
    "                      n_jobs=-1)\n",
    "knn_cv.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"Train accuracy: \", accuracy_score(y_train, knn_cv.best_estimator_.predict(X_train_transformed)))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, knn_cv.best_estimator_.predict(X_test_transformed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "D_in = X_train_transformed.shape[1]\n",
    "D_out = np.unique(y_test).shape[0]\n",
    "H = 100\n",
    "\n",
    "D_in, D_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(nn.Conv1d(1, 32, 3),\n",
    "                      nn.MaxPool1d(2),\n",
    "                      nn.ReLU(),\n",
    "                      \n",
    "                      nn.Conv1d(32, 32, 4),\n",
    "                      nn.MaxPool1d(2),\n",
    "                      nn.ReLU(),\n",
    "                      \n",
    "                      nn.Conv1d(32, 16, 3, 2),\n",
    "                      nn.ReLU(),\n",
    "                      \n",
    "                      nn.Flatten(),\n",
    "                      \n",
    "                      nn.Linear(16, 128),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(128, 32),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(32, D_out),\n",
    "                      nn.Softmax(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_normal_(m.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv1d(1, 32, kernel_size=(3,), stride=(1,))\n",
       "  (1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (2): ReLU()\n",
       "  (3): Conv1d(32, 32, kernel_size=(4,), stride=(1,))\n",
       "  (4): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (5): ReLU()\n",
       "  (6): Conv1d(32, 16, kernel_size=(3,), stride=(2,))\n",
       "  (7): ReLU()\n",
       "  (8): Flatten()\n",
       "  (9): Linear(in_features=16, out_features=128, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): Linear(in_features=128, out_features=32, bias=True)\n",
       "  (12): Sigmoid()\n",
       "  (13): Linear(in_features=32, out_features=3, bias=True)\n",
       "  (14): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model = ANN(D_in, D_out)\n",
    "\n",
    "model = model.apply(init_weights).to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(x, dtype=float):\n",
    "    x = np.asarray(x).astype(int)-1\n",
    "    n = np.unique(x).shape[0]\n",
    "    return np.eye(int(n), dtype=dtype)[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class TimeSeriesDataset(Dataset):\n",
    "    def __init__(self, X, y, device=None,):\n",
    "        super(TimeSeriesDataset, self).__init__()\n",
    "        \n",
    "        X = X[..., np.newaxis]\n",
    "        self.X = torch.tensor(X, dtype=torch.float32).permute(0,2,1)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "        \n",
    "        device_str = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        self.device = torch.device(device_str) if device is None else device\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx].to(self.device), self.y[idx].to(self.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hot_train = one_hot_encoding(y_train)\n",
    "y_hot_test = one_hot_encoding(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = TimeSeriesDataset(X_train_transformed, y_hot_train)\n",
    "dataset_test  = TimeSeriesDataset(X_test_transformed, y_hot_test)\n",
    "\n",
    "loader_train = DataLoader(dataset_train, batch_size=batch_size)\n",
    "loader_test = DataLoader(dataset_test, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 21])\n",
      "torch.Size([4, 1, 21])\n"
     ]
    }
   ],
   "source": [
    "for x, y in loader_train:\n",
    "    print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1000 \t\t || Loss:  Train 0.5332 | Validation 1.8605\n",
      "Epoch 50/1000 \t\t || Loss:  Train 0.4453 | Validation 1.8707\n",
      "Epoch 100/1000 \t\t || Loss:  Train 0.3749 | Validation 1.8698\n",
      "Epoch 150/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 200/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 250/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 300/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 350/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 400/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 450/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 500/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 550/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 600/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 650/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 700/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 750/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 800/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 850/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 900/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n",
      "Epoch 950/1000 \t\t || Loss:  Train 0.5426 | Validation 1.8607\n"
     ]
    }
   ],
   "source": [
    "num_epoch = 1000\n",
    "loss_function = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-2,)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    total_loss, total_val_loss = list(), list()\n",
    "    \n",
    "    model.train()\n",
    "    for x, y in loader_train:\n",
    "        # forward\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = loss_function(output, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss.append(loss.item())\n",
    "    \n",
    "    model.eval()\n",
    "    best_val_loss = np.inf\n",
    "    for x, y in loader_test:\n",
    "        # Compute the validation loss\n",
    "        output = model(x)\n",
    "        val_loss = loss_function(output, y)\n",
    "        total_val_loss.append(val_loss.item())\n",
    "\n",
    "        #if best_val_loss >= val_loss.item() and save_dir:\n",
    "        #    best_val_loss = val_loss.item()\n",
    "        #    torch.save(model.state_dict(), save_dir)\n",
    "    \n",
    "    freq = max(num_epoch//20, 1)\n",
    "    if epoch%freq==0:\n",
    "        print('Epoch {}/{} \\t\\t || Loss:  Train {:.4f} | Validation {:.4f}'.format(epoch, \n",
    "                                                                              num_epoch, \n",
    "                                                                              sum(total_loss), \n",
    "                                                                              sum(total_val_loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred = lambda x: np.concatenate([(model(x_i[0]).argmax(dim=1)+1).cpu().detach().numpy() for x_i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.3333333333333333\n",
      "Test accuracy:  0.3028571428571429\n"
     ]
    }
   ],
   "source": [
    "print(\"Train accuracy: \", accuracy_score(y_train, model_pred(loader_train)))\n",
    "print(\"Test accuracy: \", accuracy_score(y_test, model_pred(loader_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2524, 0.2615],\n",
       "        [0.2444, 0.2421],\n",
       "        [0.2474, 0.2345],\n",
       "        [0.2559, 0.2620]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 885,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
